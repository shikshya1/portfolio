<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Hello ðŸŒ¼ on Shikshya Dahal</title><link>https://shikshya1.github.io/portfolio/</link><description>Recent content in Hello ðŸŒ¼ on Shikshya Dahal</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 05 Nov 2022 10:58:08 -0400</lastBuildDate><atom:link href="https://shikshya1.github.io/portfolio/index.xml" rel="self" type="application/rss+xml"/><item><title>Topic modeling</title><link>https://shikshya1.github.io/portfolio/projects/topic_modeling/</link><pubDate>Sat, 05 Nov 2022 10:58:08 -0400</pubDate><guid>https://shikshya1.github.io/portfolio/projects/topic_modeling/</guid><description>Topic modeling is a statistical modeling that can be used to discover hidden (latent) themes from the collection of documents. Having information about the problems and opinions about a certain product or services can be very important for businesses. But discovering themes in a large mine of online reviews or comments in the internet can be a expensive process. Thus, several algorithms like NMF, LDA, BERT can be employed for this purpose.</description></item><item><title>Measuring Distance</title><link>https://shikshya1.github.io/portfolio/nlp/project-6/</link><pubDate>Fri, 07 Oct 2022 10:58:08 -0400</pubDate><guid>https://shikshya1.github.io/portfolio/nlp/project-6/</guid><description>Eucledian Distance Eucledian distance measures the distance between two points.
Cosine similarity Cosine similarity measures how similar the documents are irrespective of their size. Mathematically, it measures the cosine of the angle between two vectors projected in a multi-dimensional space. It is a judgment of orientation and not magnitude. The cosine similarity is advantageous because even if the two similar documents are far apart by the Euclidean distance (due to the size of the document), chances are they may still be oriented closer together.</description></item><item><title>Text Representation</title><link>https://shikshya1.github.io/portfolio/nlp/project-5/</link><pubDate>Thu, 06 Oct 2022 10:58:08 -0400</pubDate><guid>https://shikshya1.github.io/portfolio/nlp/project-5/</guid><description>Maps each word in the vocabulary(V) of the text corpus to a unique ID (integer value), then represent each sentence or document in the corpus as a V-dimensional vector.
One-Hot encoding: In one-hot encoding, each word w in the corpus vocabulary is given a unique integer ID w id that is between 1 and |V|, where V is the set of the corpus vocabulary. Each word is then represented by a V-dimensional binary vector of 0s and 1s.</description></item><item><title>NER</title><link>https://shikshya1.github.io/portfolio/nlp/project-4/</link><pubDate>Wed, 05 Oct 2022 10:58:08 -0400</pubDate><guid>https://shikshya1.github.io/portfolio/nlp/project-4/</guid><description>NER refers to the IE task of identifying the entities in a document. Entities are typically names of persons, locations, and organizations, and other specialized strings, such as money expressions, dates, products, names/numbers of laws or articles, and so on. NER is an important step in the pipeline of several NLP applications involving information extraction.
A simple approach to building an NER system is to maintain a large collection of person/organization/location names that are the most relevant to our company (e.</description></item><item><title>Text Classification</title><link>https://shikshya1.github.io/portfolio/nlp/project-3/</link><pubDate>Tue, 04 Oct 2022 10:58:08 -0400</pubDate><guid>https://shikshya1.github.io/portfolio/nlp/project-3/</guid><description>Classification categorizes data into one or more known classes. The data can be text, speech, image or numeric. Classification is used in wide range of applications across multiple domains such as: social media, healthcare, e-commerce etc. In today&amp;rsquo;s post, I will be exploring text classification.
This notebook linked with this post demostrates how to use several ML algorigthms for the disaster classification task. The models built for this purpose in this notebook are:</description></item><item><title>t-SNE</title><link>https://shikshya1.github.io/portfolio/ml/project-2/</link><pubDate>Mon, 03 Oct 2022 10:58:08 -0400</pubDate><guid>https://shikshya1.github.io/portfolio/ml/project-2/</guid><description>t-Distributed Stochastic Neighbor Embedding (t-SNE) is a unsupervised, non-parametric (non-linear) dimensionality reduction method used for visualization and exploration of high-dimensional datasets. It gives an idea of how data is arranged in higher dimension. It&amp;rsquo;s hard for us to visualize data beyond 3 dimension. Standard visualization methods can usually capture one or two variable at a time. In such cases, dimension reduction algorithm can help to analyze the pattern in the data.</description></item><item><title>Interpreting Classification Models</title><link>https://shikshya1.github.io/portfolio/nlp/project-2/</link><pubDate>Sun, 02 Oct 2022 10:58:08 -0400</pubDate><guid>https://shikshya1.github.io/portfolio/nlp/project-2/</guid><description>When we are building classification models; we are most of the time concerned about the performance criteria (how accurate the model is to classify the output labels). We donot look for explanations as to why it decided to classify the input to a certain class. But there are situations where questioning the decision of classification model becomes necessary.
Suppose we are building classifier that identifies spam emails. It identifies certain email as &amp;lsquo;spam&amp;rsquo; and moves it to spam folder rather than placing it in inbox folder without the need of human intervention.</description></item><item><title/><link>https://shikshya1.github.io/portfolio/aws/project-2/</link><pubDate>Sat, 01 Oct 2022 10:58:08 -0400</pubDate><guid>https://shikshya1.github.io/portfolio/aws/project-2/</guid><description>Create a trigger to upload data in csv files to DynamoDB when csv is inserted on S3 via Lambda function using Serverless Framework This template demonstrates how to process a csv file when inserted on s3 bucket and use the data to populate DynamoDB table. DynamoDB is a fully managed, serverless, key-value NoSQL database designed to run high-performance applications at any scale.I am only using DynamoDB in this project for test purpose as it is a bad choice when we are dealing with small size of data.</description></item><item><title>Deploy lambda function with external python packages using serverless framework.</title><link>https://shikshya1.github.io/portfolio/aws/project-1/</link><pubDate>Sat, 01 Oct 2022 10:58:08 -0400</pubDate><guid>https://shikshya1.github.io/portfolio/aws/project-1/</guid><description>Lambda Function &amp;amp; Layers: AWS Lambda is a computing service that allows us to run our code without the overhead of configuring and managing a server. It can be scaled automatically based on the request and the charge is calculated only for the compute time. Lambda function can be deployed using .zip file archive that contains function and the dependency or using container image. Lambda layers can be used to package external dependencies that is required to run lambda function.</description></item><item><title>Feature Scaling</title><link>https://shikshya1.github.io/portfolio/ml/project-1/</link><pubDate>Sat, 01 Oct 2022 10:58:08 -0400</pubDate><guid>https://shikshya1.github.io/portfolio/ml/project-1/</guid><description>Feature scaling is one of the most important transformation in most of the ML projects. When one feature is on small range; say 0 to 10 while the other one is on a large range (suppose 0 to 10000); ML algorithms donot perform well. We have to scale the features so that both of them takes a comparable ranges of values to each other. In simpler terms, it means transforming data into a common range of values.</description></item><item><title>Exploratory Data Analysis</title><link>https://shikshya1.github.io/portfolio/statistics/project-1/</link><pubDate>Tue, 07 Apr 2020 10:58:08 -0400</pubDate><guid>https://shikshya1.github.io/portfolio/statistics/project-1/</guid><description>Statistics is the study of how to collect, organize, analyze and interpret numerical information and data.
There are two major terms repeated frequently in the statistics domain: population and sample.
Population: It refers to the group of people or objects with common theme. Example: Technical team at Target. Sample: It refers to the small portion of population. Example: only UX designers at target. Exploratory data analysis (EDA): EDA is one of the most important step in any data science project.</description></item><item><title>NLP 1: NLP pipelines</title><link>https://shikshya1.github.io/portfolio/nlp/project-1/</link><pubDate>Tue, 07 Apr 2020 10:58:08 -0400</pubDate><guid>https://shikshya1.github.io/portfolio/nlp/project-1/</guid><description>NLP :
&amp;ldquo;As we all know, dealing with natural language is hard. It is hard from the standpoint of the child, who must spend many years acquiring a language (compare this time span to that required for the acquisition of motor skills such as eating solids, walking, or swimming), it is hard for the adult language learner, it is hard for the scientist who attempts to model the relevant phenomena, and it is hard for the engineer who attempts to build systems that deal with natural language input or output.</description></item><item><title>Sampling and bias</title><link>https://shikshya1.github.io/portfolio/statistics/project-2/</link><pubDate>Tue, 07 Apr 2020 10:58:08 -0400</pubDate><guid>https://shikshya1.github.io/portfolio/statistics/project-2/</guid><description>The rise of big data in today&amp;rsquo;s world might raise a misconception that we donot need sampling anymore. But it is even more relevant in today&amp;rsquo;s world as we have to deal with data from variety of sources and to minimize bias.It is impractical and unnecessary to measure the whole population. It also helps to save resources.
Sampling frame: List of individuals from which the sample is selected.
Types:
Simple random sampling (SRS): A simple random sample of n measurements from a population is a subset of the population is a subset of the population selected in such a way that sample of size n from the population has an equal chance of being selected.</description></item><item><title/><link>https://shikshya1.github.io/portfolio/statistics/project-3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shikshya1.github.io/portfolio/statistics/project-3/</guid><description/></item><item><title>About</title><link>https://shikshya1.github.io/portfolio/about/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shikshya1.github.io/portfolio/about/</guid><description>Hi. My Name is Shikshya Dahal. I am an Information Management Graduate with specialization in Data Science and AI. Currently, I&amp;rsquo;m working as a Machine Learning Developer and most of my works are in NLP and Conversational AI. Data science has always been my passion. I am good at handling data and I have a solid foundation and experience in building ML and statistical models. I find exploring and visualizing insights hidden in data to develop data driven solutions that aids in decision making more than admirable.</description></item></channel></rss>
<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>Day 2- Interpreting Classification Models | Shikshya Dahal</title><meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content="Interpreting Classification Models When we are building classification models; we are most of the time concerned about the performance criteria (how accurate the model is to classify the output labels). We donot look for explanations as to why it decided to classify the input to a certain class. But there are situations where questioning the decision of classification model becomes necessary.
Suppose we are building classifier that identifies psam emails. It identifies certain email as &lsquo;spam&rsquo; and moves it to spam folder rather than placing it in inbox folder without the need of human intervention."><meta name=generator content="Hugo 0.104.3"><meta name=robots content="noindex, nofollow"><link rel=stylesheet href=/portfolio/ananke/css/main.min.css><meta property="og:title" content="Day 2- Interpreting Classification Models"><meta property="og:description" content="Interpreting Classification Models When we are building classification models; we are most of the time concerned about the performance criteria (how accurate the model is to classify the output labels). We donot look for explanations as to why it decided to classify the input to a certain class. But there are situations where questioning the decision of classification model becomes necessary.
Suppose we are building classifier that identifies psam emails. It identifies certain email as &lsquo;spam&rsquo; and moves it to spam folder rather than placing it in inbox folder without the need of human intervention."><meta property="og:type" content="article"><meta property="og:url" content="https://shikshya1.github.io/portfolio/30-days-of-ml/project-2/"><meta property="article:section" content="30 Days of ML"><meta property="article:published_time" content="2020-09-01T10:58:08-04:00"><meta property="article:modified_time" content="2020-09-01T10:58:08-04:00"><meta property="og:site_name" content="Shikshya Dahal"><meta itemprop=name content="Day 2- Interpreting Classification Models"><meta itemprop=description content="Interpreting Classification Models When we are building classification models; we are most of the time concerned about the performance criteria (how accurate the model is to classify the output labels). We donot look for explanations as to why it decided to classify the input to a certain class. But there are situations where questioning the decision of classification model becomes necessary.
Suppose we are building classifier that identifies psam emails. It identifies certain email as &lsquo;spam&rsquo; and moves it to spam folder rather than placing it in inbox folder without the need of human intervention."><meta itemprop=datePublished content="2020-09-01T10:58:08-04:00"><meta itemprop=dateModified content="2020-09-01T10:58:08-04:00"><meta itemprop=wordCount content="360"><meta itemprop=keywords content="Normalization,ML,"><meta name=twitter:card content="summary"><meta name=twitter:title content="Day 2- Interpreting Classification Models"><meta name=twitter:description content="Interpreting Classification Models When we are building classification models; we are most of the time concerned about the performance criteria (how accurate the model is to classify the output labels). We donot look for explanations as to why it decided to classify the input to a certain class. But there are situations where questioning the decision of classification model becomes necessary.
Suppose we are building classifier that identifies psam emails. It identifies certain email as &lsquo;spam&rsquo; and moves it to spam folder rather than placing it in inbox folder without the need of human intervention."></head><body class="ma0 avenir bg-near-white"><header class="cover bg-top" style=background-image:url(https://shikshya1.github.io/portfolio/images/cpv.jpg)><div class=bg-black-60><nav class="pv3 ph3 ph4-ns" role=navigation><div class="flex-l justify-between items-center center"><a href=/portfolio/ class="f3 fw2 hover-white no-underline white-90 dib">Shikshya Dahal</a><div class="flex-l items-center"><ul class="pl0 mr3"><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/portfolio/about/ title="About page">About</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/portfolio/30-days-of-ml/ title="30 Days of ML page">30 Days of ML</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/portfolio/contact/ title="Contact page">Contact</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/portfolio/nlp/ title="NLP page">NLP</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/portfolio/post/ title="Projects page">Projects</a></li></ul><div class=ananke-socials><a href=https://github.com/shikshya1 target=_blank class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="GitHub link" rel=noopener aria-label="follow on GitHub——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 512 512" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M256 32C132.3 32 32 134.8 32 261.7c0 101.5 64.2 187.5 153.2 217.9 11.2 2.1 15.3-5 15.3-11.1.0-5.5-.2-19.9-.3-39.1-62.3 13.9-75.5-30.8-75.5-30.8-10.2-26.5-24.9-33.6-24.9-33.6-20.3-14.3 1.5-14 1.5-14 22.5 1.6 34.3 23.7 34.3 23.7 20 35.1 52.4 25 65.2 19.1 2-14.8 7.8-25 14.2-30.7-49.7-5.8-102-25.5-102-113.5.0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8.0.0 18.8-6.2 61.6 23.5 17.9-5.1 37-7.6 56.1-7.7 19 .1 38.2 2.6 56.1 7.7 42.8-29.7 61.5-23.5 61.5-23.5 12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6.0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5.0 30.7-.3 55.5-.3 63 0 6.1 4 13.3 15.4 11C415.9 449.1 480 363.1 480 261.7 480 134.8 379.7 32 256 32z"/></svg></span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a></div></div></div></nav><div class="tc-l pv6 ph3 ph4-ns"><h1 class="f2 f1-l fw2 white-90 mb0 lh-title">Day 2- Interpreting Classification Models</h1></div></div></header><main class=pb7 role=main><article class="flex-l flex-wrap justify-between mw8 center ph3"><header class="mt4 w-100"><aside class="instapaper_ignoref b helvetica tracked">30 DAYS OF ML</aside><div id=sharing class="mt3 ananke-socials"></div><h1 class="f1 athelas mt3 mb1">Day 2- Interpreting Classification Models</h1><time class="f6 mv4 dib tracked" datetime=2020-09-01T10:58:08-04:00>September 1, 2020</time></header><div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><h1 id=interpreting-classification-models>Interpreting Classification Models</h1><p>When we are building classification models; we are most of the time concerned about the performance criteria (how accurate the model is to classify the output labels). We donot look for explanations as to why it decided to classify the input to a certain class. But there are situations where questioning the decision of classification model becomes necessary.</p><p>Suppose we are building classifier that identifies psam emails. It identifies certain email as &lsquo;spam&rsquo; and moves it to spam folder rather than placing it in inbox folder without the need of human intervention. But no NLP models are 100% accurate. We still arenot able to build language models that can accurately understand ambiguity and complexity of natural language. So, if we have a certain way to explian what features are prominent in making a decision whether to mark an email as ham or spam will help humans to understand the model and how it will perform in other similar real world data. As the interest in interpretability of model is growing, explaining predictions of model will help to assessing trust of people using it. We can use LIME and Shap for this purpose.</p><h2 id=lime-local-interpretable-model-agnostic-explanations>LIME (Local Interpretable Model-agnostic Explanations)</h2><p>The main reason that author proposed LIME in the original paper was to understand the reasons behind predictions of machine learning models that are usually treated as black box. The authors have argued that is important to trust a model to behave in reasonable ways while using for decision making pupose where predictions cannot be acted upon on blind faith. LIME learns an interpretable model locally around the prediction. LIME builds sparse linear models around an individual prediction in its local vicinity.</p><h2 id=shap-shapley-additive-explanations>SHAP (SHapley Additive exPlanations)</h2><p>SHAP assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties.</p><p>References:</p><p><a href=https://arxiv.org/pdf/1602.04938.pdf>https://arxiv.org/pdf/1602.04938.pdf</a> : Why Should I Trust You?”
Explaining the Predictions of Any Classifier</p><p><a href=https://arxiv.org/abs/1705.07874>https://arxiv.org/abs/1705.07874</a> : A Unified Approach to Interpreting Model Predictions</p><h3 id=link-to-github-page-codehttpsgithubcomshikshya130_days_of_mltreemainday-220interpreting20classification20models>Link to github page: <a href=https://github.com/shikshya1/30_days_of_ml/tree/main/Day-2%20(Interpreting%20classification%20models)>Code</a></h3><ul class=pa0><li class="list di"><a href=/tags/normalization class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Normalization</a></li><li class="list di"><a href=/tags/ml class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">ML</a></li></ul><div class="mt6 instapaper_ignoref"></div></div><aside class="w-30-l mt6-l"><div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links"><p class="f5 b mb3">Related</p><ul class="pa0 list"><li class=mb2><a href=/portfolio/30-days-of-ml/project-1/>Day 1- Feature Scaling</a></li></ul></div></aside></article></main><footer class="bg-black bottom-0 w-100 pa3" role=contentinfo><div class="flex justify-between"><a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3"></a><div><div class=ananke-socials><a href=https://github.com/shikshya1 target=_blank class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="GitHub link" rel=noopener aria-label="follow on GitHub——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 512 512" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M256 32C132.3 32 32 134.8 32 261.7c0 101.5 64.2 187.5 153.2 217.9 11.2 2.1 15.3-5 15.3-11.1.0-5.5-.2-19.9-.3-39.1-62.3 13.9-75.5-30.8-75.5-30.8-10.2-26.5-24.9-33.6-24.9-33.6-20.3-14.3 1.5-14 1.5-14 22.5 1.6 34.3 23.7 34.3 23.7 20 35.1 52.4 25 65.2 19.1 2-14.8 7.8-25 14.2-30.7-49.7-5.8-102-25.5-102-113.5.0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8.0.0 18.8-6.2 61.6 23.5 17.9-5.1 37-7.6 56.1-7.7 19 .1 38.2 2.6 56.1 7.7 42.8-29.7 61.5-23.5 61.5-23.5 12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6.0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5.0 30.7-.3 55.5-.3 63 0 6.1 4 13.3 15.4 11C415.9 449.1 480 363.1 480 261.7 480 134.8 379.7 32 256 32z"/></svg></span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a></div></div></div></footer></body></html>
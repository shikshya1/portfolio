<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>Clustering Amazon books based on book title | Shikshya Dahal</title><meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content="Dataset: The dataset contains 946 books obtained from scraping Amazon books.
Reference: https://www.kaggle.com/datasets/die9origephit/amazon-data-science-books
Read DataFrame
df= pd.read_csv('CSVPATH') Representing text using TF-IDF
from sklearn.feature_extraction.text import TfidfVectorizer vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1,2)) X = vectorizer.fit_transform(df[&#34;title&#34;]) Clustering: For the clustering, KMeans is used. KMeans is an unsupervised learning method that clusters dataset into &lsquo;k&rsquo; different clusters. Each sample is assigned to the cluster with the nearest mean and then the means are updated during iterative optimization process."><meta name=generator content="Hugo 0.108.0"><meta name=robots content="noindex, nofollow"><link rel=stylesheet href=/portfolio/ananke/css/main.min.css><meta property="og:title" content="Clustering Amazon books based on book title"><meta property="og:description" content="Dataset: The dataset contains 946 books obtained from scraping Amazon books.
Reference: https://www.kaggle.com/datasets/die9origephit/amazon-data-science-books
Read DataFrame
df= pd.read_csv('CSVPATH') Representing text using TF-IDF
from sklearn.feature_extraction.text import TfidfVectorizer vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1,2)) X = vectorizer.fit_transform(df[&#34;title&#34;]) Clustering: For the clustering, KMeans is used. KMeans is an unsupervised learning method that clusters dataset into &lsquo;k&rsquo; different clusters. Each sample is assigned to the cluster with the nearest mean and then the means are updated during iterative optimization process."><meta property="og:type" content="article"><meta property="og:url" content="https://shikshya1.github.io/portfolio/ml/project-3/"><meta property="article:section" content="ML"><meta property="article:published_time" content="2023-01-01T10:58:08-04:00"><meta property="article:modified_time" content="2023-01-01T10:58:08-04:00"><meta property="og:site_name" content="Shikshya Dahal"><meta itemprop=name content="Clustering Amazon books based on book title"><meta itemprop=description content="Dataset: The dataset contains 946 books obtained from scraping Amazon books.
Reference: https://www.kaggle.com/datasets/die9origephit/amazon-data-science-books
Read DataFrame
df= pd.read_csv('CSVPATH') Representing text using TF-IDF
from sklearn.feature_extraction.text import TfidfVectorizer vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1,2)) X = vectorizer.fit_transform(df[&#34;title&#34;]) Clustering: For the clustering, KMeans is used. KMeans is an unsupervised learning method that clusters dataset into &lsquo;k&rsquo; different clusters. Each sample is assigned to the cluster with the nearest mean and then the means are updated during iterative optimization process."><meta itemprop=datePublished content="2023-01-01T10:58:08-04:00"><meta itemprop=dateModified content="2023-01-01T10:58:08-04:00"><meta itemprop=wordCount content="472"><meta itemprop=keywords content="kmeans,clustering,"><meta name=twitter:card content="summary"><meta name=twitter:title content="Clustering Amazon books based on book title"><meta name=twitter:description content="Dataset: The dataset contains 946 books obtained from scraping Amazon books.
Reference: https://www.kaggle.com/datasets/die9origephit/amazon-data-science-books
Read DataFrame
df= pd.read_csv('CSVPATH') Representing text using TF-IDF
from sklearn.feature_extraction.text import TfidfVectorizer vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1,2)) X = vectorizer.fit_transform(df[&#34;title&#34;]) Clustering: For the clustering, KMeans is used. KMeans is an unsupervised learning method that clusters dataset into &lsquo;k&rsquo; different clusters. Each sample is assigned to the cluster with the nearest mean and then the means are updated during iterative optimization process."></head><body class="ma0 avenir bg-near-white"><header class="cover bg-top" style=background-image:url(https://shikshya1.github.io/portfolio/images/cpv.jpg)><div class=bg-black-60><nav class="pv3 ph3 ph4-ns" role=navigation><div class="flex-l justify-between items-center center"><a href=/portfolio/ class="f3 fw2 hover-white no-underline white-90 dib">Shikshya Dahal</a><div class="flex-l items-center"><ul class="pl0 mr3"><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/portfolio/about/ title="About page">About</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/portfolio/aws/ title="AWS page">AWS</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/portfolio/ml/ title="ML Basics page">ML Basics</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/portfolio/nlp/ title="NLP page">NLP</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/portfolio/projects/ title="Projects page">Projects</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/portfolio/statistics/ title="Statistics page">Statistics</a></li></ul><div class=ananke-socials><a href=https://github.com/shikshya1 target=_blank class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="GitHub link" rel=noopener aria-label="follow on GitHub——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 512 512" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M256 32C132.3 32 32 134.8 32 261.7c0 101.5 64.2 187.5 153.2 217.9 11.2 2.1 15.3-5 15.3-11.1.0-5.5-.2-19.9-.3-39.1-62.3 13.9-75.5-30.8-75.5-30.8-10.2-26.5-24.9-33.6-24.9-33.6-20.3-14.3 1.5-14 1.5-14 22.5 1.6 34.3 23.7 34.3 23.7 20 35.1 52.4 25 65.2 19.1 2-14.8 7.8-25 14.2-30.7-49.7-5.8-102-25.5-102-113.5.0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8.0.0 18.8-6.2 61.6 23.5 17.9-5.1 37-7.6 56.1-7.7 19 .1 38.2 2.6 56.1 7.7 42.8-29.7 61.5-23.5 61.5-23.5 12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6.0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5.0 30.7-.3 55.5-.3 63 0 6.1 4 13.3 15.4 11C415.9 449.1 480 363.1 480 261.7 480 134.8 379.7 32 256 32z"/></svg></span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a></div></div></div></nav><div class="tc-l pv6 ph3 ph4-ns"><h1 class="f2 f1-l fw2 white-90 mb0 lh-title">Clustering Amazon books based on book title</h1></div></div></header><main class=pb7 role=main><article class="flex-l flex-wrap justify-between mw8 center ph3"><header class="mt4 w-100"><aside class="instapaper_ignoref b helvetica tracked">ML BASICS</aside><div id=sharing class="mt3 ananke-socials"></div><h1 class="f1 athelas mt3 mb1">Clustering Amazon books based on book title</h1><time class="f6 mv4 dib tracked" datetime=2023-01-01T10:58:08-04:00>January 1, 2023</time></header><div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><h3 id=dataset>Dataset:</h3><p>The dataset contains 946 books obtained from scraping Amazon books.</p><p>Reference: <a href=https://www.kaggle.com/datasets/die9origephit/amazon-data-science-books>https://www.kaggle.com/datasets/die9origephit/amazon-data-science-books</a></p><p>Read DataFrame</p><pre tabindex=0><code>df= pd.read_csv(&#39;CSVPATH&#39;)
</code></pre><p>Representing text using TF-IDF</p><pre tabindex=0><code>from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer = TfidfVectorizer(stop_words=&#39;english&#39;, ngram_range=(1,2))
X = vectorizer.fit_transform(df[&#34;title&#34;])
</code></pre><h3 id=clustering>Clustering:</h3><p>For the clustering, KMeans is used. KMeans is an unsupervised learning method that clusters dataset into &lsquo;k&rsquo; different clusters. Each sample is assigned to the cluster with the nearest mean and then the means are updated during iterative optimization process.</p><p>Steps:</p><ol><li>Initialize random cluster centers</li><li>Repeat until converged:</li></ol><ul><li>Update cluster points: Assign data points to the nearest cluster centroid</li><li>Update cluster centers: set center to the mean of each cluster</li></ul><p>Calculating &lsquo;K&rsquo; in KMeans:</p><p>There are several methods to calculate number of clusters in KMeans. Elbow method is one of the most popular method to calculate optimal number of &lsquo;K&rsquo;. The iterative approach is to calculate Within-Cluster-Sum of Squared Errors (WSS) for different values of k. The squared distance between the data point and its predicted centroid is calculated using distance metrics like Eucledian or Manhattan distance.The sum of all squared errors of all data points gives WSS. Then, we choose the value of K where the WSS starts to diminish and forms an elbow like shape as the optimal cluster number.</p><pre tabindex=0><code>from sklearn.cluster import KMeans
sum_of_squared_distances = []
K = range(2,10)
for k in K:
   km = KMeans(n_clusters=k, max_iter=600, n_init=10)
   km.fit(X)
   sum_of_squared_distances.append(km.inertia_)
</code></pre><p>Plot number of clusters wrt sum of squared distance to determine the optimal number of cluster. In this dataset, We can see a elbow shape forming at cluster 6. So, we will use that as optimal number of cluster in our dataset.</p><p>Fit the model and assign cluster to book label.</p><pre tabindex=0><code>optimal_k = 6
model = KMeans(n_clusters=optimal_k, init=&#39;k-means++&#39;, max_iter=600, n_init=10)
model.fit(X)

labels = model.labels_
book_cluster = pd.DataFrame(list(zip(df[&#34;title&#34;],labels)),columns=[&#39;title&#39;,&#39;cluster&#39;])
</code></pre><p>Naming clusters based on the top features on each clusters:</p><p>Cluster number 0 => statistics and probability</p><p>Cluster number 1 => Data Science</p><p>Cluster number 2 => Machine Learning</p><p>Cluster number 3 => Data Analysis</p><p>Cluster number 4 => Deep Learning</p><p>Cluster number 5 => Python</p><pre tabindex=0><code>cluster number 0
(&#39;statistics&#39;, &#39;probability&#39;, &#39;practice&#39;, &#39;data&#39;, &#39;introduction&#39;, &#39;dummies&#39;, &#39;probability statistics&#39;, &#39;applications&#39;, &#39;sciences&#39;, &#39;business&#39;, &#39;ap&#39;, &#39;ap statistics&#39;, &#39;behavioral&#39;, &#39;statistics applications&#39;, &#39;practice statistics&#39;)


cluster number 1
(&#39;data&#39;, &#39;science&#39;, &#39;data science&#39;, &#39;analytics&#39;, &#39;python&#39;, &#39;guide&#39;, &#39;data analytics&#39;, &#39;learning&#39;, &#39;series&#39;, &#39;using&#39;, &#39;introduction&#39;, &#39;business&#39;, &#39;machine learning&#39;, &#39;machine&#39;, &#39;beginners&#39;)


cluster number 2
(&#39;learning&#39;, &#39;machine&#39;, &#39;machine learning&#39;, &#39;data&#39;, &#39;introduction&#39;, &#39;python&#39;, &#39;edition&#39;, &#39;series&#39;, &#39;introduction machine&#39;, &#39;algorithms&#39;, &#39;computation&#39;, &#39;computation machine&#39;, &#39;engineering&#39;, &#39;science&#39;, &#39;end&#39;)


cluster number  3
(&#39;data&#39;, &#39;analysis&#39;, &#39;data analysis&#39;, &#39;using&#39;, &#39;python&#39;, &#39;qualitative&#39;, &#39;statistics&#39;, &#39;introduction&#39;, &#39;social&#39;, &#39;guide&#39;, &#39;methods&#39;, &#39;analysis using&#39;, &#39;practical&#39;, &#39;qualitative data&#39;, &#39;sciences&#39;)


cluster number  4
(&#39;learning&#39;, &#39;deep&#39;, &#39;deep learning&#39;, &#39;python&#39;, &#39;intelligence&#39;, &#39;artificial&#39;, &#39;artificial intelligence&#39;, &#39;neural&#39;, &#39;tensorflow&#39;, &#39;machine&#39;, &#39;networks&#39;, &#39;machine learning&#39;, &#39;neural networks&#39;, &#39;learning python&#39;, &#39;pytorch&#39;)


cluster number  5
(&#39;python&#39;, &#39;programming&#39;, &#39;edition&#39;, &#39;data&#39;, &#39;guide&#39;, &#39;learning&#39;, &#39;learn&#39;, &#39;python programming&#39;, &#39;using&#39;, &#39;algorithms&#39;, &#39;introduction&#39;, &#39;2nd edition&#39;, &#39;2nd&#39;, &#39;build&#39;, &#39;code&#39;)
</code></pre><h3 id=link-to-github-page-codehttpsgithubcomshikshya1ml_basicstreemainkmeans20clustering>Link to github page: <a href=https://github.com/shikshya1/ML_Basics/tree/main/KMeans%20clustering>Code</a></h3><ul class=pa0><li class="list di"><a href=/tags/kmeans class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">kmeans</a></li><li class="list di"><a href=/tags/clustering class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">clustering</a></li></ul><div class="mt6 instapaper_ignoref"></div></div><aside class="w-30-l mt6-l"></aside></article></main><footer class="bg-black bottom-0 w-100 pa3" role=contentinfo><div class="flex justify-between"><a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3"></a><div><div class=ananke-socials><a href=https://github.com/shikshya1 target=_blank class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="GitHub link" rel=noopener aria-label="follow on GitHub——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 512 512" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M256 32C132.3 32 32 134.8 32 261.7c0 101.5 64.2 187.5 153.2 217.9 11.2 2.1 15.3-5 15.3-11.1.0-5.5-.2-19.9-.3-39.1-62.3 13.9-75.5-30.8-75.5-30.8-10.2-26.5-24.9-33.6-24.9-33.6-20.3-14.3 1.5-14 1.5-14 22.5 1.6 34.3 23.7 34.3 23.7 20 35.1 52.4 25 65.2 19.1 2-14.8 7.8-25 14.2-30.7-49.7-5.8-102-25.5-102-113.5.0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8.0.0 18.8-6.2 61.6 23.5 17.9-5.1 37-7.6 56.1-7.7 19 .1 38.2 2.6 56.1 7.7 42.8-29.7 61.5-23.5 61.5-23.5 12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6.0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5.0 30.7-.3 55.5-.3 63 0 6.1 4 13.3 15.4 11C415.9 449.1 480 363.1 480 261.7 480 134.8 379.7 32 256 32z"/></svg></span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a></div></div></div></footer></body></html>
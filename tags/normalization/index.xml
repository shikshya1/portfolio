<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Normalization on Shikshya Dahal</title><link>https://shikshya1.github.io/portfolio/tags/normalization/</link><description>Recent content in Normalization on Shikshya Dahal</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 01 Oct 2022 10:58:08 -0400</lastBuildDate><atom:link href="https://shikshya1.github.io/portfolio/tags/normalization/index.xml" rel="self" type="application/rss+xml"/><item><title>Feature Scaling</title><link>https://shikshya1.github.io/portfolio/ml/project-1/</link><pubDate>Sat, 01 Oct 2022 10:58:08 -0400</pubDate><guid>https://shikshya1.github.io/portfolio/ml/project-1/</guid><description>Feature scaling is one of the most important transformation in most of the ML projects. When one feature is on small range; say 0 to 10 while the other one is on a large range (suppose 0 to 10000); ML algorithms donot perform well. We have to scale the features so that both of them takes a comparable ranges of values to each other. In simpler terms, it means transforming data into a common range of values.</description></item></channel></rss>
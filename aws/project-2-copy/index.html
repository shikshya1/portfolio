<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>Create a trigger to upload records from csv to DynamoDB when csv file is inserted on S3 via Lambda function using Serverless Framework | Shikshya Dahal</title><meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content="This project demonstrates how to process a csv file when inserted on s3 bucket and use the data to populate DynamoDB table. DynamoDB is a fully managed, serverless, key-value NoSQL database designed to run high-performance applications at any scale.I am only using DynamoDB in this project for test purpose as it is a bad choice when we are dealing with small size of data.
Steps Initialize a aws-python template from serverless framework We then need to import boto3 (Python SDK that allows us to interact with DynamoDB and S3), pandas and s3fs (to read the csv file) library."><meta name=generator content="Hugo 0.108.0"><meta name=robots content="noindex, nofollow"><link rel=stylesheet href=/portfolio/ananke/css/main.min.css><meta property="og:title" content="Create a trigger to upload records from csv to DynamoDB when csv file is inserted on S3 via Lambda function using Serverless Framework "><meta property="og:description" content="This project demonstrates how to process a csv file when inserted on s3 bucket and use the data to populate DynamoDB table. DynamoDB is a fully managed, serverless, key-value NoSQL database designed to run high-performance applications at any scale.I am only using DynamoDB in this project for test purpose as it is a bad choice when we are dealing with small size of data.
Steps Initialize a aws-python template from serverless framework We then need to import boto3 (Python SDK that allows us to interact with DynamoDB and S3), pandas and s3fs (to read the csv file) library."><meta property="og:type" content="article"><meta property="og:url" content="https://shikshya1.github.io/portfolio/aws/project-2-copy/"><meta property="article:section" content="AWS"><meta property="article:published_time" content="2022-10-01T10:58:08-04:00"><meta property="article:modified_time" content="2022-10-01T10:58:08-04:00"><meta property="og:site_name" content="Shikshya Dahal"><meta itemprop=name content="Create a trigger to upload records from csv to DynamoDB when csv file is inserted on S3 via Lambda function using Serverless Framework "><meta itemprop=description content="This project demonstrates how to process a csv file when inserted on s3 bucket and use the data to populate DynamoDB table. DynamoDB is a fully managed, serverless, key-value NoSQL database designed to run high-performance applications at any scale.I am only using DynamoDB in this project for test purpose as it is a bad choice when we are dealing with small size of data.
Steps Initialize a aws-python template from serverless framework We then need to import boto3 (Python SDK that allows us to interact with DynamoDB and S3), pandas and s3fs (to read the csv file) library."><meta itemprop=datePublished content="2022-10-01T10:58:08-04:00"><meta itemprop=dateModified content="2022-10-01T10:58:08-04:00"><meta itemprop=wordCount content="398"><meta itemprop=keywords content="Serverless,AWS Lambda,"><meta name=twitter:card content="summary"><meta name=twitter:title content="Create a trigger to upload records from csv to DynamoDB when csv file is inserted on S3 via Lambda function using Serverless Framework "><meta name=twitter:description content="This project demonstrates how to process a csv file when inserted on s3 bucket and use the data to populate DynamoDB table. DynamoDB is a fully managed, serverless, key-value NoSQL database designed to run high-performance applications at any scale.I am only using DynamoDB in this project for test purpose as it is a bad choice when we are dealing with small size of data.
Steps Initialize a aws-python template from serverless framework We then need to import boto3 (Python SDK that allows us to interact with DynamoDB and S3), pandas and s3fs (to read the csv file) library."></head><body class="ma0 avenir bg-near-white"><header class="cover bg-top" style=background-image:url(https://shikshya1.github.io/portfolio/images/cpv.jpg)><div class=bg-black-60><nav class="pv3 ph3 ph4-ns" role=navigation><div class="flex-l justify-between items-center center"><a href=/portfolio/ class="f3 fw2 hover-white no-underline white-90 dib">Shikshya Dahal</a><div class="flex-l items-center"><ul class="pl0 mr3"><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/portfolio/about/ title="About page">About</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/portfolio/aws/ title="AWS page">AWS</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/portfolio/ml/ title="ML Basics page">ML Basics</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/portfolio/nlp/ title="NLP page">NLP</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/portfolio/projects/ title="Projects page">Projects</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/portfolio/statistics/ title="Statistics page">Statistics</a></li></ul><div class=ananke-socials><a href=https://github.com/shikshya1 target=_blank class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="GitHub link" rel=noopener aria-label="follow on GitHub——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 512 512" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M256 32C132.3 32 32 134.8 32 261.7c0 101.5 64.2 187.5 153.2 217.9 11.2 2.1 15.3-5 15.3-11.1.0-5.5-.2-19.9-.3-39.1-62.3 13.9-75.5-30.8-75.5-30.8-10.2-26.5-24.9-33.6-24.9-33.6-20.3-14.3 1.5-14 1.5-14 22.5 1.6 34.3 23.7 34.3 23.7 20 35.1 52.4 25 65.2 19.1 2-14.8 7.8-25 14.2-30.7-49.7-5.8-102-25.5-102-113.5.0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8.0.0 18.8-6.2 61.6 23.5 17.9-5.1 37-7.6 56.1-7.7 19 .1 38.2 2.6 56.1 7.7 42.8-29.7 61.5-23.5 61.5-23.5 12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6.0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5.0 30.7-.3 55.5-.3 63 0 6.1 4 13.3 15.4 11C415.9 449.1 480 363.1 480 261.7 480 134.8 379.7 32 256 32z"/></svg></span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a></div></div></div></nav><div class="tc-l pv6 ph3 ph4-ns"><h1 class="f2 f1-l fw2 white-90 mb0 lh-title">Create a trigger to upload records from csv to DynamoDB when csv file is inserted on S3 via Lambda function using Serverless Framework</h1></div></div></header><main class=pb7 role=main><article class="flex-l flex-wrap justify-between mw8 center ph3"><header class="mt4 w-100"><aside class="instapaper_ignoref b helvetica tracked">AWS</aside><div id=sharing class="mt3 ananke-socials"></div><h1 class="f1 athelas mt3 mb1">Create a trigger to upload records from csv to DynamoDB when csv file is inserted on S3 via Lambda function using Serverless Framework</h1><time class="f6 mv4 dib tracked" datetime=2022-10-01T10:58:08-04:00>October 1, 2022</time></header><div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><p>This project demonstrates how to process a csv file when inserted on s3 bucket and use the data to populate DynamoDB table. DynamoDB is a fully managed, serverless, key-value NoSQL database designed to run high-performance applications at any scale.I am only using DynamoDB in this project for test purpose as it is a bad choice when we are dealing with small size of data.</p><h2 id=steps>Steps</h2><h4 id=initialize-a-aws-python-template-from-serverless-framework>Initialize a aws-python template from serverless framework</h4><p>We then need to import boto3 (Python SDK that allows us to interact with DynamoDB and S3), pandas and s3fs (to read the csv file) library. We need to create a reference to our s3 bucket and DynamoDB table using:</p><pre tabindex=0><code>client = boto3.client(&#39;s3&#39;)
dynamodb = boto3.resource(&#39;dynamodb&#39;)
table = dynamodb.Table(&#39;&lt;TABLE-NAME&gt;&#39;)
</code></pre><p>The snapshot of the dataframe that I will be working with is displayed below.</p><p>BatchNumber and StudentId columns are used as partition key and sort in DynamoDB table respectively.</p><p>We will extract the information about the csv path through Amazon S3 Event Notifications and read the records. We will then use batch writer to write objects to Amazon DynamoDB in batch.</p><pre tabindex=0><code>for item in event.get(&#34;Records&#34;):
        s3 = item.get(&#34;s3&#34;)
        bucket = s3.get(&#34;bucket&#34;).get(&#34;name&#34;)
        key = s3.get(&#34;object&#34;).get(&#34;key&#34;)

        print(&#34;bucket&#34;, bucket)
        print(&#34;key&#34;, key)

        path = &#34;s3://&#34; + bucket+ &#34;/&#34; + key
        df = pd.read_csv(path, delimiter=&#39;\t&#39;)

        print(df.columns)

        with table.batch_writer() as batch:
            for index, row in df.iterrows():
                batch.put_item(json.loads(row.to_json()))
</code></pre><h3 id=serverlessyaml-file-walkthrough>serverless.yaml file walkthrough</h3><h4 id=manage-permission>Manage permission</h4><p>We will need proper IAM Permissions in order to read file from s3 bucket and interact with DynamoDB. Inside the serverless.yml file make the following adjustments:</p><pre tabindex=0><code>iamRoleStatements:
    - Effect: Allow
      Action:
        - s3:*
      Resource: 
       - &#39;arn:aws:s3:::&lt;bucket-name&gt;/*&#39;
    - Effect: Allow
      Action:
        - dynamodb:*
      Resource:
        - arn:aws:dynamodb:us-east-1:************:table/&lt;table-name&gt;
</code></pre><h4 id=layers>Layers</h4><p>As we will need pandas and s3fs to read the csv files, I will be providing the ARN&rsquo;s of the lambda layers of both of these libraries that I created while working on different project.</p><pre tabindex=0><code>layers:
        - arn:aws:lambda:us-east-1:************:layer:pandas-numpy:1
        - arn:aws:lambda:us-east-1:************:layer:s3fs:3
</code></pre><h4 id=event-definition>Event definition</h4><p>The hello function is called whenever a document with .csv extension is uploaded to s3 bucket. This will reference the existing s3 bucket defined if existing is set to true.</p><pre tabindex=0><code>functions:
  hello:
    handler: handler.hello
    events:
        - s3:
            bucket: &lt;Bucket-name&gt;
            event: s3:ObjectCreated:*
            rules:
              - prefix: &lt;prefix-if-any&gt;/
              - suffix: .csv
            existing: true
</code></pre><h4 id=deploy>Deploy</h4><p>Deploy the application using sls deploy. Thus whenever a new file is inserted in the defined s3 bucket, the records will be inserted in the DynamoDB table.</p><h3 id=link-to-github-page-codehttpsgithubcomshikshya1aws-serverlesstreemains3-trigger-event>Link to github page: <a href=https://github.com/shikshya1/aws-serverless/tree/main/s3-trigger-event>Code</a></h3><ul class=pa0><li class="list di"><a href=/tags/serverless class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Serverless</a></li><li class="list di"><a href=/tags/aws-lambda class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">AWS Lambda</a></li></ul><div class="mt6 instapaper_ignoref"></div></div><aside class="w-30-l mt6-l"><div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links"><p class="f5 b mb3">Related</p><ul class="pa0 list"><li class=mb2><a href=/portfolio/aws/project-1/>Deploy lambda function with external python packages using serverless framework.</a></li><li class=mb2><a href=/portfolio/aws/project-2/>Create a trigger to upload records from csv to DynamoDB when csv file is inserted on S3 via Lambda function using Serverless Framework</a></li></ul></div></aside></article></main><footer class="bg-black bottom-0 w-100 pa3" role=contentinfo><div class="flex justify-between"><a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3"></a><div><div class=ananke-socials><a href=https://github.com/shikshya1 target=_blank class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="GitHub link" rel=noopener aria-label="follow on GitHub——Opens in a new window"><span class=icon><svg style="enable-background:new 0 0 512 512" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M256 32C132.3 32 32 134.8 32 261.7c0 101.5 64.2 187.5 153.2 217.9 11.2 2.1 15.3-5 15.3-11.1.0-5.5-.2-19.9-.3-39.1-62.3 13.9-75.5-30.8-75.5-30.8-10.2-26.5-24.9-33.6-24.9-33.6-20.3-14.3 1.5-14 1.5-14 22.5 1.6 34.3 23.7 34.3 23.7 20 35.1 52.4 25 65.2 19.1 2-14.8 7.8-25 14.2-30.7-49.7-5.8-102-25.5-102-113.5.0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8.0.0 18.8-6.2 61.6 23.5 17.9-5.1 37-7.6 56.1-7.7 19 .1 38.2 2.6 56.1 7.7 42.8-29.7 61.5-23.5 61.5-23.5 12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6.0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5.0 30.7-.3 55.5-.3 63 0 6.1 4 13.3 15.4 11C415.9 449.1 480 363.1 480 261.7 480 134.8 379.7 32 256 32z"/></svg></span><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd"/></svg></span></a></div></div></div></footer></body></html>